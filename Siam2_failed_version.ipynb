{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Siam2_failed_version.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuuuwoo/Video_tracking788/blob/main/Siam2_failed_version.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaP9DTRyX-ru",
        "outputId": "d691d17c-e2e1-46dd-8b5e-9b44ac7e86c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RM4tR9niStSp"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Project')"
      ],
      "metadata": {
        "id": "Ii1VBSQ5S_ug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/zzh142857/SiameseFC-tf.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W_Y9RhpmT3Ep",
        "outputId": "17ea6f1c-a907-4180-bad3-d3f54d570786"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'SiameseFC-tf' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Project/SiameseFC-tf')"
      ],
      "metadata": {
        "id": "sTk4TYVuUdbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.mkdir('./data')"
      ],
      "metadata": {
        "id": "BogAwoeiUjhA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "a9823ac0-34a5-4639-8de3-ff6b8dc22952"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-5349b2791966>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./data'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: './data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('./data')\n",
        "os.mkdir('./training')\n",
        "os.mkdir('./row_data')\n",
        "os.mkdir('./testing')"
      ],
      "metadata": {
        "id": "AQ3WQ4RIVChI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive/Project/SiameseFC-tf')"
      ],
      "metadata": {
        "id": "ulM7yPw1XC0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import os.path\n",
        "from src.region_to_bbox import region_to_bbox_normalized\n",
        "from random import shuffle\n",
        "\n",
        "\n",
        "def prepare_shuffled_list(data, output, directory, num):\n",
        "    \"\"\"\n",
        "        Input:\n",
        "            data_folder: relative path of folder who contains all the vedio folders for training.\n",
        "            tfrecord_name: nameof the tfrecord file\n",
        "            output_directory: relative dir which will contain the tfrecord file\n",
        "    \"\"\"\n",
        "    if not os.path.exists(directory) or os.path.isfile(directory):\n",
        "        os.makedirs(directory)\n",
        "        \n",
        "    \n",
        "        \n",
        "    Dir = os.getcwd()\n",
        "    data = os.path.join(Dir, data)\n",
        "    #get a list of dirs in data_folder, in each of which contains a training vedio\n",
        "    vedio_folder_list = sorted([dir for dir in os.listdir(data) if not os.path.isfile(os.path.join(data, dir))])[:num]\n",
        "    vedio_index = 0\n",
        "    output_list = []\n",
        "\n",
        "    #loop through all the vedio folders\n",
        "    for vedio_folder in vedio_folder_list:\n",
        "        print(\"Reading images from \" + vedio_folder);\n",
        "        vedio_index += 1\n",
        "        \n",
        "        vedio_folder = os.path.join(data, vedio_folder)\n",
        "        #get a list of dirs in data_folder, in each of which contains a training vedio\n",
        "        file_list = [dir for dir in os.listdir(os.path.join(vedio_folder,'img')) if os.path.isfile(os.path.join(os.path.join(vedio_folder,'img'), dir))]\n",
        "        img_list = sorted([file for file in file_list if file.endswith(\".jpg\")])\n",
        "        print(len(img_list))\n",
        "        \n",
        "        gt_file_name = 'groundtruth_rect.txt'        \n",
        "        print(vedio_folder,gt_file_name)\n",
        "        if vedio_folder=='/content/drive/MyDrive/Project/SiameseFC-tf/data/Human4':\n",
        "          gt_file_name='groundtruth_rect.2.txt'\n",
        "        assert os.path.exists(os.path.join(vedio_folder, gt_file_name))\n",
        "        \n",
        "        gt_file = open(os.path.join(vedio_folder, gt_file_name), 'r')\n",
        "\n",
        "\n",
        "        gts = gt_file.readlines()\n",
        "        for i in range(len(gts)):\n",
        "          line=gts[i].replace('\\t',',')\n",
        "          gts[i]=line\n",
        "        print(len(gts))\n",
        "        #check if num of ground truth equals the num of img files\n",
        "        if len(gts)>len(img_list):\n",
        "          gts=gts[:len(img_list)]\n",
        "        elif len(img_list)>len(gts):\n",
        "          img_list=img_list[:len(gts)]\n",
        "        assert len(gts) == len(img_list)\n",
        "        _examples = list(zip(img_list, gts))\n",
        "        \n",
        "        #prepare examplar z\n",
        "        z = os.path.join(os.path.join(vedio_folder, 'img'), img_list[0])\n",
        "        z_img = cv2.imread(z)\n",
        "        z_gt = gts[0].strip(\"\\n\").split(\",\") \n",
        "        print(z_gt)  \n",
        "        assert len(z_gt) == 4\n",
        "        #x, y in ground truth is the coordinate of the topleft corner, we need to convert to the center\n",
        "        z_pos_x, z_pos_y, z_target_w, z_target_h = region_to_bbox_normalized(z_gt, z_img.shape[1], z_img.shape[0])\n",
        "               \n",
        "        for _example in _examples[1: ]:\n",
        "            assert len(_example) == 2\n",
        "            gt = _example[1].strip(\"\\n\").split(\",\") \n",
        "            assert len(gt) == 4\n",
        "            \n",
        "            x = os.path.join(os.path.join(vedio_folder, 'img'), _example[0])\n",
        "            x_img = cv2.imread(x)                                    \n",
        "            x_pos_x, x_pos_y, x_target_w, x_target_h = region_to_bbox_normalized(gt, x_img.shape[1], x_img.shape[0]) \n",
        "            \n",
        "            \n",
        "            output_list.append(z + \" \" + x + \" \" + str(z_pos_x)+ \" \"+ str(z_pos_y)+ \" \"+  str(z_target_w)+ \" \"+ str(z_target_h)+ \" \"+  str(x_pos_x)+ \" \"+ str(x_pos_y)+ \" \"+  str(x_target_w)+ \" \"+  str(x_target_h))\n",
        "            z = x\n",
        "            z_pos_x, z_pos_y, z_target_w, z_target_h = x_pos_x, x_pos_y, x_target_w, x_target_h\n",
        "    print(\"Finished loading all the training data. Start shuffling...\")\n",
        "    shuffle(output_list);\n",
        "    with open(os.path.join(directory,output) + \".txt\",\"w+\") as f:\n",
        "        for output_file in output_list:\n",
        "            f.write(output_file + \"\\n\") \n",
        "    print(\"Done. tfrecords file saved at \" + directory)\n",
        "        \n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    prepare_shuffled_list(\"data\", \"shuffled_data_list\", \"tfrecords\", num = 35)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af6xys1QWe15",
        "outputId": "ae71e52e-a9a9-4ff7-a80d-82c2b9de39bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading images from Basketball\n",
            "725\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Basketball groundtruth_rect.txt\n",
            "725\n",
            "['198', '214', '34', '81']\n",
            "Reading images from Biker\n",
            "142\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Biker groundtruth_rect.txt\n",
            "142\n",
            "['262', '94', '16', '26']\n",
            "Reading images from Bird1\n",
            "408\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Bird1 groundtruth_rect.txt\n",
            "408\n",
            "['450', '91', '31', '37']\n",
            "Reading images from BlurBody\n",
            "334\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/BlurBody groundtruth_rect.txt\n",
            "334\n",
            "['400', '48', '87', '319']\n",
            "Reading images from BlurCar2\n",
            "585\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/BlurCar2 groundtruth_rect.txt\n",
            "585\n",
            "['227', '207', '122', '99']\n",
            "Reading images from BlurFace\n",
            "493\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/BlurFace groundtruth_rect.txt\n",
            "493\n",
            "['246', '226', '94', '114']\n",
            "Reading images from BlurOwl\n",
            "631\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/BlurOwl groundtruth_rect.txt\n",
            "631\n",
            "['352', '197', '56', '100']\n",
            "Reading images from Bolt\n",
            "350\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Bolt groundtruth_rect.txt\n",
            "350\n",
            "['336', '165', '26', '61']\n",
            "Reading images from Box\n",
            "1161\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Box groundtruth_rect.txt\n",
            "1161\n",
            "['478', '143', '80', '111']\n",
            "Reading images from Car1\n",
            "1020\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Car1 groundtruth_rect.txt\n",
            "1020\n",
            "['23', '88', '66', '55']\n",
            "Reading images from Car4\n",
            "659\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Car4 groundtruth_rect.txt\n",
            "659\n",
            "['70', '51', '107', '87']\n",
            "Reading images from CarDark\n",
            "393\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/CarDark groundtruth_rect.txt\n",
            "393\n",
            "['73', '126', '29', '23']\n",
            "Reading images from CarScale\n",
            "252\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/CarScale groundtruth_rect.txt\n",
            "252\n",
            "['6', '166', '42', '26']\n",
            "Reading images from ClifBar\n",
            "472\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/ClifBar groundtruth_rect.txt\n",
            "472\n",
            "['143', '125', '30', '54']\n",
            "Reading images from Couple\n",
            "140\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Couple groundtruth_rect.txt\n",
            "140\n",
            "['51', '47', '25', '62']\n",
            "Reading images from Crowds\n",
            "347\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Crowds groundtruth_rect.txt\n",
            "347\n",
            "['561', '311', '22', '51']\n",
            "Reading images from David\n",
            "770\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/David groundtruth_rect.txt\n",
            "471\n",
            "['129', '80', '64', '78']\n",
            "Reading images from Deer\n",
            "71\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Deer groundtruth_rect.txt\n",
            "71\n",
            "['306', '5', '95', '65']\n",
            "Reading images from Diving\n",
            "231\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Diving groundtruth_rect.txt\n",
            "215\n",
            "['177', '51', '21', '129']\n",
            "Reading images from DragonBaby\n",
            "113\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/DragonBaby groundtruth_rect.txt\n",
            "113\n",
            "['160', '83', '56', '65']\n",
            "Reading images from Dudek\n",
            "1145\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Dudek groundtruth_rect.txt\n",
            "1145\n",
            "['123', '87', '132', '176']\n",
            "Reading images from Football\n",
            "362\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Football groundtruth_rect.txt\n",
            "362\n",
            "['310', '102', '39', '50']\n",
            "Reading images from Freeman4\n",
            "297\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Freeman4 groundtruth_rect.txt\n",
            "283\n",
            "['125', '86', '15', '16']\n",
            "Reading images from Girl\n",
            "500\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Girl groundtruth_rect.txt\n",
            "500\n",
            "['57', '21', '31', '45']\n",
            "Reading images from Human3\n",
            "1698\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Human3 groundtruth_rect.txt\n",
            "1698\n",
            "['264', '311', '37', '69']\n",
            "Reading images from Human4\n",
            "667\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Human4 groundtruth_rect.txt\n",
            "667\n",
            "['99', '237', '27', '82']\n",
            "Reading images from Human6\n",
            "792\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Human6 groundtruth_rect.txt\n",
            "792\n",
            "['340', '358', '18', '55']\n",
            "Reading images from Human9\n",
            "305\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Human9 groundtruth_rect.txt\n",
            "305\n",
            "['93', '113', '34', '109']\n",
            "Reading images from Ironman\n",
            "166\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Ironman groundtruth_rect.txt\n",
            "166\n",
            "['206', '85', '49', '57']\n",
            "Reading images from Jump\n",
            "122\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Jump groundtruth_rect.txt\n",
            "122\n",
            "['136', '35', '52', '182']\n",
            "Reading images from Jumping\n",
            "313\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Jumping groundtruth_rect.txt\n",
            "313\n",
            "['147', '110', '34', '33']\n",
            "Reading images from Liquor\n",
            "1741\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Liquor groundtruth_rect.txt\n",
            "1741\n",
            "['256', '152', '73', '210']\n",
            "Reading images from Matrix\n",
            "100\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Matrix groundtruth_rect.txt\n",
            "100\n",
            "['331', '39', '38', '42']\n",
            "Reading images from MotorRolling\n",
            "164\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/MotorRolling groundtruth_rect.txt\n",
            "164\n",
            "['117', '68', '122', '125']\n",
            "Reading images from Panda\n",
            "1000\n",
            "/content/drive/MyDrive/Project/SiameseFC-tf/data/Panda groundtruth_rect.txt\n",
            "1000\n",
            "['58', '100', '28', '23']\n",
            "Finished loading all the training data. Start shuffling...\n",
            "Done. tfrecords file saved at tfrecords\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import os.path\n",
        "from src.parse_arguments import parse_arguments\n",
        "\n",
        "\n",
        "def transform2tfrecord(data_file, tfrecord_name, output_directory, resize_width, resize_height):\n",
        "    \"\"\"\n",
        "        Input:\n",
        "            data_folder: relative path of folder who contains all the vedio folders for training.\n",
        "            tfrecord_name: nameof the tfrecord file\n",
        "            output_directory: relative dir which will contain the tfrecord file\n",
        "\n",
        "    \"\"\"\n",
        "    if not os.path.exists(output_directory) or os.path.isfile(output_directory):\n",
        "        os.makedirs(output_directory)\n",
        "        \n",
        "    #init tfrecord file\n",
        "    filename = os.path.join(output_directory, tfrecord_name + '.tfrecords')\n",
        "    writer = tf.io.TFRecordWriter(filename)\n",
        "        \n",
        "    cur_dir = os.getcwd()\n",
        "    data_folder = os.path.join(\"tfrecords\", data_file)\n",
        "    with open(data_folder, \"r\") as f:\n",
        "        print(\"Generating tfrecord from \" + data_folder)\n",
        "        data_list = f.readlines()\n",
        "        for data in data_list:\n",
        "            z, x, z_pos_x, z_pos_y, z_target_w, z_target_h, x_pos_x, x_pos_y, x_target_w, x_target_h = data.strip(\"\\n \").split(\" \")\n",
        "            z_pos_x = float(z_pos_x)\n",
        "            z_pos_y = float(z_pos_y)\n",
        "            z_target_w = float(z_target_w)\n",
        "            z_target_h = float(z_target_h)\n",
        "            x_pos_x = float(x_pos_x)\n",
        "            x_pos_y = float(x_pos_y)\n",
        "            x_target_w = float(x_target_w)\n",
        "            x_target_h = float(x_target_h)\n",
        "            z_img = cv2.imread(z)\n",
        "            z_img = cv2.resize(z_img, (resize_width,resize_height))\n",
        "            x_img = cv2.imread(x)\n",
        "            x_img = cv2.resize(x_img, (resize_width,resize_height))\n",
        "            z_raw = z_img.tostring()\n",
        "            x_raw = x_img.tostring()\n",
        "            \n",
        "\n",
        "            example = tf.train.Example(features=tf.train.Features(feature={\n",
        "                'z_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[z_raw])),\n",
        "                'x_raw': tf.train.Feature(bytes_list=tf.train.BytesList(value=[x_raw])),\n",
        "                'z_pos_x': tf.train.Feature(float_list=tf.train.FloatList(value=[z_pos_x])),\n",
        "                'z_pos_y': tf.train.Feature(float_list=tf.train.FloatList(value=[z_pos_y])),\n",
        "                'z_target_w': tf.train.Feature(float_list=tf.train.FloatList(value=[z_target_w])),\n",
        "                'z_target_h': tf.train.Feature(float_list=tf.train.FloatList(value=[z_target_h])),\n",
        "                'x_pos_x': tf.train.Feature(float_list=tf.train.FloatList(value=[x_pos_x])),\n",
        "                'x_pos_y': tf.train.Feature(float_list=tf.train.FloatList(value=[x_pos_y])),\n",
        "                'x_target_w': tf.train.Feature(float_list=tf.train.FloatList(value=[x_target_w])),\n",
        "                'x_target_h': tf.train.Feature(float_list=tf.train.FloatList(value=[x_target_h]))\n",
        "                \n",
        "            }))\n",
        "            writer.write(example.SerializeToString())\n",
        "        \n",
        "        \n",
        " \n",
        "        \n",
        "    writer.close()\n",
        "    print(\"Writer closed.\")\n",
        "    print(tfrecord_name + '.tfrecords'+\" is written to \"+output_directory)\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "if __name__ == \"__main__\":\n",
        "    hp, evaluation, run, env, design = parse_arguments()\n",
        "    transform2tfrecord(\"shuffled_data_list.txt\", \"training_dataset\", \"tfrecords\", resize_width = design.resize_width, resize_height = design.resize_height)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drh5fL9h5fQT",
        "outputId": "b1d1d43e-7953-4fa4-a56c-7393907e15bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating tfrecord from tfrecords/shuffled_data_list.txt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:42: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:43: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writer closed.\n",
            "training_dataset.tfrecords is written to tfrecords\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bmf7Vedaoiv",
        "outputId": "2a9f1680-1533-4e20-9e4a-f0ec5c554503"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "import sys\n",
        "import os\n",
        "os.chdir('/content/drive/MyDrive/Project/SiameseFC-tf')\n",
        "import src.siamese as siam\n",
        "from src.trainer import trainer\n",
        "from src.parse_arguments import parse_arguments\n",
        "import src.read_training_dataset\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "    training procedure:\n",
        "    1,input z, x, pos_x, pos_y, w, d and gt of x\n",
        "    2,pad and crop z,x\n",
        "    3,calculate score map\n",
        "    4,calculate loss\n",
        "    5,bp, update variable\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "def train():\n",
        "    # avoid printing TF debugging information\n",
        "    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "    # TODO: allow parameters from command line or leave everything in json files?\n",
        "    hp, evaluation, run, env, design = parse_arguments()\n",
        "    # Set size for use with tf.image.resize_images with align_corners=True.\n",
        "    # For example,\n",
        "    #   [1 4 7] =>   [1 2 3 4 5 6 7]    (length 3*(3-1)+1)\n",
        "    # instead of\n",
        "    # [1 4 7] => [1 1 2 3 4 5 6 7 7]  (length 3*3)\n",
        "    final_score_sz = hp.response_up * (design.score_sz - 1) + 1\n",
        "    \n",
        "    # build the computational graph of Siamese fully-convolutional network\n",
        "    siamNet = siam.Siamese(design.batch_size)\n",
        "    # get tensors that will be used during training\n",
        "    image, z_crops, x_crops, templates_z, scores, loss, train_step, distance_to_gt, summary= siamNet.build_tracking_graph_train(final_score_sz, design, env, hp)\n",
        " \n",
        "    # read tfrecodfile holding all the training data\n",
        "    data_reader = src.read_training_dataset.myReader(design.resize_width, design.resize_height, design.channel)\n",
        "    batched_data = data_reader.read_tfrecord(os.path.join(env.tfrecord_path, env.tfrecord_filename), num_epochs = design.num_epochs, batch_size = design.batch_size)\n",
        "    \n",
        "    # run trainer\n",
        "    trainer(hp, run, design, final_score_sz, batched_data, image, templates_z, scores, loss, train_step, distance_to_gt,  z_crops, x_crops, siamNet, summary)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    sys.exit(train())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "nMDeHwYmM5ps",
        "outputId": "f8641489-ccf1-4d20-c4c6-a30bc0cf2624"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-183425082d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-183425082d9b>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;31m# build the computational graph of Siamese fully-convolutional network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0msiamNet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msiam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSiamese\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdesign\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;31m# get tensors that will be used during training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_crops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_crops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemplates_z\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdistance_to_gt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0msiamNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_tracking_graph_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_score_sz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesign\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/Project/SiameseFC-tf/src/siamese.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# define all the placeholders in the net\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatched_pos_x_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatched_pos_y_ph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
          ]
        }
      ]
    }
  ]
}